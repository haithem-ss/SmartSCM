{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f16fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\",\"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c01e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haithem/Documents/PFE/Proof_of_Concept/src/testing/llm_as_a_judge.py:67: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  self.llm=Ollama(model=\"cas/nous-hermes-2-mistral-7b-dpo:latest\")\n",
      "/Users/haithem/Documents/PFE/Proof_of_Concept/src/testing/llm_as_a_judge.py:77: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  self.chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from testing.llm_as_a_judge import AnswerJudge\n",
    "\n",
    "judge = AnswerJudge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcfb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "question = \"show me the quantity of orders that were cancelled in 2023 \"\n",
    "generated_answer = 'The system cannot answer this question because the available data only covers from 2024-12-01 to 2025-05-20, and the requested data is for 2023.'\n",
    "reference_answer = \"The system cannot answer this question because the data does not contain that information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d31f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haithem/Documents/PFE/Proof_of_Concept/src/testing/llm_as_a_judge.py:94: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  raw_output = self.chain.run(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "output = judge.evaluate(\n",
    "        question=question,\n",
    "        reference_answer=reference_answer,\n",
    "        generated_answer=generated_answer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97aed60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verdict': True, 'method': 'LLM-as-a-judge'}\n",
      "Verdict: True\n",
      "Method: LLM-as-a-judge\n"
     ]
    }
   ],
   "source": [
    "print(output)\n",
    "print(\"Verdict:\", output[\"verdict\"])\n",
    "print(\"Method:\", output[\"method\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
